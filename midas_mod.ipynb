{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "filled-enclosure",
   "metadata": {
    "id": "filled-enclosure"
   },
   "source": [
    "#Mod of Midas to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-progressive",
   "metadata": {
    "attributes": {
     "classes": [
      "shell"
     ],
     "id": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "heard-progressive",
    "outputId": "b638ed7f-c405-49a6-aaf4-307d1df7af78"
   },
   "outputs": [],
   "source": [
    "pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-kernel",
   "metadata": {
    "id": "southwest-kernel"
   },
   "source": [
    "### Example Usage\n",
    "\n",
    "Download an image from the PyTorch homepage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-charter",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "modern-charter",
    "outputId": "0d228565-163e-432d-a3c1-00e7b66419c6"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import urllib.request\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-discrimination",
   "metadata": {
    "id": "foreign-discrimination"
   },
   "source": [
    "Load a model (see [https://github.com/intel-isl/MiDaS/#Accuracy](https://github.com/intel-isl/MiDaS/#Accuracy) for an overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-receiver",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158,
     "referenced_widgets": [
      "2e76cd2e375e4435bd46ab690f12654e",
      "c1bbe52789c144e4a172e981b1094b68",
      "f77d148004634aa1ad50c5ed11185dbe",
      "e89eed54a68b45348d69952aa17062ca",
      "625d14b426684555bae45dbc5b12fca3",
      "0bdaef72a4894f52ae067633bfe1e540",
      "b747debb1f34499fb0a319c04ce86b3d",
      "801d3094342248c0bbc354e897cb6623",
      "842c2816f0e24d578390c6d30847fd87",
      "a1dfe6781b5249a6848d78fa231b2c52",
      "d1f5411037574dc98b11356a7fac06ee"
     ]
    },
    "id": "verified-receiver",
    "outputId": "6a48011f-ed7d-4cf6-8d96-aee8ae5315d1"
   },
   "outputs": [],
   "source": [
    "model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
    "#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
    "#model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
    "\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-bloom",
   "metadata": {
    "id": "enabling-bloom"
   },
   "source": [
    "Move model to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-subscription",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sunrise-subscription",
    "outputId": "2627c624-6638-47a7-8b34-213cee40cec8"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "midas.to(device)\n",
    "midas.eval()\n",
    "()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BrZodx8HapAk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrZodx8HapAk",
    "outputId": "2314488a-d530-4bdc-e954-3de64d319a10"
   },
   "outputs": [],
   "source": [
    "for (name, layer) in midas._modules.items():\n",
    "    #iteration over outer layers\n",
    "    print((name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t676pYSTcVjn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t676pYSTcVjn",
    "outputId": "8ffcb513-7ae8-4be3-bd02-d32045db57f9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "cudnn.benchmark = True\n",
    "\n",
    "from models import ResNet\n",
    "from metrics import AverageMeter, Result\n",
    "from dataloaders.dense_to_sparse import UniformSampling, SimulatedStereo,ORBSampling\n",
    "import criteria\n",
    "import utils\n",
    "from dataloaders.nyu_dataloader import NYUDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cae0de-295b-4efb-8ece-6788c6561b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=os.path.join('data', 'nyudepthv2', 'train')\n",
    "test_dir=os.path.join('data', 'nyudepthv2', 'val')\n",
    "\n",
    "sparsifier=UniformSampling(100,np.inf)\n",
    "train_dataset = NYUDataset(train_dir, type='train', sparsifier=sparsifier,modality='rgbd')\n",
    "val_dataset = NYUDataset(test_dir, type='val', sparsifier=sparsifier,modality='rgbd')\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=10, shuffle=True,\n",
    "            num_workers=1, pin_memory=True, sampler=None,\n",
    "            worker_init_fn=lambda work_id:np.random.seed(work_id))\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "        batch_size=1, shuffle=False, num_workers=10, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-wallet",
   "metadata": {
    "id": "antique-wallet"
   },
   "source": [
    "Load transforms to resize and normalize the image for large or small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e19f27-e107-4e2b-8152-bb113d0346f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9c407-f3c1-4f93-916c-9e6337dc45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input, target) in enumerate(train_loader):\n",
    "    print(input.shape)\n",
    "    print(target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb0b3c-8e67-44ef-91bf-2b97c07f7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=input[0,:3].permute(1,2,0)\n",
    "plt.imshow(d)\n",
    "#print(torch.nonzero(d).shape)\n",
    "print(d[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-penguin",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prepared-penguin",
    "outputId": "060636dd-7707-4843-965c-d4e0aba0e63f"
   },
   "outputs": [],
   "source": [
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "\n",
    "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
    "    transform = midas_transforms.dpt_transform\n",
    "else:\n",
    "    transform = midas_transforms.small_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-reservoir",
   "metadata": {
    "id": "former-reservoir"
   },
   "source": [
    "Load image and apply transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-platinum",
   "metadata": {
    "id": "engaged-platinum"
   },
   "outputs": [],
   "source": [
    "print(np.shape(input[:1,:3].permute(0,2,3,1)*255))\n",
    "input_batch=transform(np.array(input[0,:3].permute(1,2,0))*255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49fee15-e4c8-47e6-91b0-4c586d416322",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a0477-c748-4f98-b720-cc4dd368bd78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "running-investment",
   "metadata": {
    "id": "running-investment"
   },
   "source": [
    "Predict and resize to original resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-atlantic",
   "metadata": {
    "id": "historic-atlantic"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = midas(input_batch.cuda())\n",
    "\n",
    "    prediction = torch.nn.functional.interpolate(\n",
    "        prediction.unsqueeze(1),\n",
    "        size=d.shape[:2],\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    ).squeeze()\n",
    "\n",
    "output = prediction.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-kitty",
   "metadata": {
    "id": "fifty-kitty"
   },
   "source": [
    "Show result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-economics",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "spoken-economics",
    "outputId": "b5d7842c-449f-4d2a-9a18-277f775548a0"
   },
   "outputs": [],
   "source": [
    "plt.imshow(output.squeeze())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XFTez_rRlXGh",
   "metadata": {
    "id": "XFTez_rRlXGh"
   },
   "source": [
    "Let's try to modify the model to include partial depth informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5vrQvNellWee",
   "metadata": {
    "id": "5vrQvNellWee"
   },
   "outputs": [],
   "source": [
    "#First, let's fix the pretrained values :\n",
    "for parameter in midas.parameters(): \n",
    "    parameter.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sryFoPChlgJA",
   "metadata": {
    "id": "sryFoPChlgJA"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.md = midas\n",
    "        self.fcomb = nn.Conv2d(2,1,(21,21),padding=(10,10),padding_mode='reflect')\n",
    "        self.ReLU=nn.ReLU()\n",
    "    def forward(self, x, y):\n",
    "        x1 = self.md(x)\n",
    "        x2 = self.fcomb(torch.cat((x1.unsqueeze(1),y),1))\n",
    "        x3 = self.ReLU(x2)\n",
    "        return x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jzOjF2JeoxM3",
   "metadata": {
    "id": "jzOjF2JeoxM3"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "x=input_batch\n",
    "res=midas(input_batch.cuda())\n",
    "y=torch.zeros_like(res)\n",
    "lx,ly=res.shape[1],res.shape[2]\n",
    "for _ in range(180):\n",
    "  i,j=random.randint(0,lx-1),random.randint(0,ly-1)\n",
    "  y[0,i,j]=res[0,i,j]\n",
    "y=y.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711681c0-b7d8-4111-a608-b6af852ec23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rqPJVrJKtQkS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqPJVrJKtQkS",
    "outputId": "f95759af-a498-497d-dab7-701645274857"
   },
   "outputs": [],
   "source": [
    "model=MyModel()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "#res=model(x.cuda(),y.cuda())\n",
    "()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68eb100-97e6-4c28-891c-85a672352766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "def train( model, dataloader, loss, optimizer, n_epochs=1):\n",
    "    model.train(True)\n",
    "    i=torch.Tensor(0).cuda()\n",
    "    for epoch in range(n_epochs):\n",
    "        track_loss=[]\n",
    "        for _, (input, ref) in enumerate(dataloader):\n",
    "            x2=torch.zeros((np.shape(input)[0],3,288,384))\n",
    "            for i in range(np.shape(x)[0]):\n",
    "                x2[i]=transform(np.array(input[0,:3].permute(1,2,0))*255)\n",
    "            y= transforms.Resize((288,384),antialias=True)(input[:,2:3])\n",
    "            ref=transforms.Resize((288,384),antialias=True)(ref)\n",
    "            res=model(x2.cuda(),y.cuda())\n",
    "            l=loss(res,ref.cuda())\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            track_loss.append(l.cpu())\n",
    "            \n",
    "            #print(f\"[{(i+1)//10}] avg_loss : {sum(track_loss)/len(track_loss)}\")\n",
    "            if len(track_loss) % 1 == 0:\n",
    "                print(f\"[{(len(track_loss))//10}] avg_loss : {sum(track_loss[-min(len(track_loss),10):])/min(len(track_loss),10)}\")\n",
    "                #track_loss=[]\n",
    "                #i=10\n",
    "            i= i+1\n",
    "    return mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1795c8b-af11-463a-9a8b-6f5c2ba29539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import MSELoss\n",
    "loss=MSELoss()\n",
    "optimizer=SGD(model.parameters(),lr=10**-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279974b1-8740-4b71-8f4b-7069fa34ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,train_loader,loss,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49333ec7-639a-4e82-a885-b6f67e3d45fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x2.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5f0e6-ecb2-486b-ae2b-a9068f3706b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction2 = model(input_batch.cuda(),transforms.Resize((288,384),antialias=True)(input[:1,2:3]).cuda())\n",
    "\n",
    "    prediction2 = torch.nn.functional.interpolate(\n",
    "        prediction2,\n",
    "        size=d.shape[:2],\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    ).squeeze()\n",
    "\n",
    "output = prediction.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209c5cc-8a81-4e49-b8ba-a4ec163885f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853cf9fa-14d8-4212-8dcb-ec587781cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(prediction2.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead5b81-7f6c-417b-bde6-cc88c9e20752",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = midas(input_batch.cuda())\n",
    "\n",
    "    prediction = torch.nn.functional.interpolate(\n",
    "        prediction.unsqueeze(0),\n",
    "        size=d.shape[:2],\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    ).squeeze()\n",
    "\n",
    "output = prediction.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc7a70a-3397-4d4e-9e63-605a0420d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0f9d4-604b-4247-b288-71571019721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss(prediction2.cpu(),transforms.Resize((228, 304),antialias=True)(target)[0,0]),loss(prediction.cpu(),-transforms.Resize((228, 304),antialias=True)(target)[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6a773-b9b9-43ba-93d4-928fdfd9ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(-target[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9cef4b-9078-4828-a701-dc068dc595e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(sum(prediction2)))\n",
    "pred=prediction+torch.min(prediction)\n",
    "pred2=prediction2+torch.min(prediction)\n",
    "p1=pred/(sum(sum(pred))/(prediction.shape[0]*prediction.shape[1]))\n",
    "p2=pred2/(sum(sum(pred2))/(p2.shape[0]*p2.shape[1]))\n",
    "rf=transforms.Resize((228, 304),antialias=True)(target)[0,0]\n",
    "rf=rf+torch.min(rf)\n",
    "pr=rf/(sum(sum(rf))/(rf.shape[0]*rf.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a37e3-38b9-48cc-addb-28e329864c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(p1.cpu(),rf.cpu()),loss(p2.cpu(),rf.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2cbf80-8f4b-4a99-8489-f7ee0e62e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave(\"p2opp.png\", -p2.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f063c-4f51-4bae-a128-10435a8844d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We try with ORB-samples now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a906d665-e0d7-407b-8540-9981176a5b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=os.path.join('data', 'nyudepthv2', 'train')\n",
    "test_dir=os.path.join('data', 'nyudepthv2', 'val')\n",
    "\n",
    "sparsifier=ds.ORBSampling(100,np.inf)\n",
    "train_dataset = NYUDataset(train_dir, type='train', sparsifier=sparsifier,modality='rgbd')\n",
    "val_dataset = NYUDataset(test_dir, type='val', sparsifier=sparsifier,modality='rgbd')\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=10, shuffle=True,\n",
    "            num_workers=1, pin_memory=True, sampler=None,\n",
    "            worker_init_fn=lambda work_id:np.random.seed(work_id))\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "        batch_size=1, shuffle=False, num_workers=10, pin_memory=True)\n",
    "\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "\n",
    "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
    "    transform = midas_transforms.dpt_transform\n",
    "else:\n",
    "    transform = midas_transforms.small_transform\n",
    "\n",
    "for parameter in midas.parameters(): \n",
    "    parameter.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3dcf37-5065-4b50-9904-5842014a2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.md = midas\n",
    "        self.fcomb = nn.Conv2d(2,2,(21,21),padding=(10,10),padding_mode='reflect')\n",
    "        self.f2 = nn.Conv2d(2,1,(21,21),padding=(10,10),padding_mode='reflect')\n",
    "        self.ReLU=nn.ReLU()\n",
    "    def forward(self, x, y):\n",
    "        x1 = self.md(x)\n",
    "        x2 = self.fcomb(torch.cat((x1.unsqueeze(1),y),1))\n",
    "        x3 = self.ReLU(x2)\n",
    "        x4 = self.f2(x3)\n",
    "        return x4\n",
    "model=MyModel()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481ce2c-56e2-4a83-97f6-d911f31286d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "def train( model, dataloader, loss, optimizer, n_epochs=1):\n",
    "    model.train(True)\n",
    "    i=torch.Tensor(0).cuda()\n",
    "    for epoch in range(n_epochs):\n",
    "        track_loss=[]\n",
    "        for _, (input, ref) in enumerate(dataloader):\n",
    "            x2=torch.zeros((np.shape(input)[0],3,288,384))\n",
    "            for i in range(np.shape(x2)[0]):\n",
    "                x2[i]=transform(np.array(input[0,:3].permute(1,2,0))*255)\n",
    "            y= transforms.Resize((288,384),antialias=True)(input[:,2:3])\n",
    "            ref=transforms.Resize((288,384),antialias=True)(ref)\n",
    "            res=model(x2.cuda(),y.cuda())\n",
    "            l=loss(res,ref.cuda())\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            track_loss.append(l.cpu())\n",
    "            \n",
    "            #print(f\"[{(i+1)//10}] avg_loss : {sum(track_loss)/len(track_loss)}\")\n",
    "            if len(track_loss) % 10 == 0:\n",
    "                print(f\"[{(len(track_loss))//10}] avg_loss : {sum(track_loss[-min(len(track_loss),10):])/min(len(track_loss),10)}\")\n",
    "                #track_loss=[]\n",
    "                #i=10\n",
    "            i= i+1\n",
    "    return track_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73619836-f73d-4853-8b0a-2e523b4e7020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import MSELoss\n",
    "loss=MSELoss()\n",
    "optimizer=SGD(model.parameters(),lr=10**-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcc01eb-ae89-4944-8659-d5ae08b4dbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "losses=train(model,train_loader,loss,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a4751-579c-4a75-98a0-3360b61bf97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    eval_loss=[]\n",
    "    for  _,(input, ref) in enumerate(test_loader):\n",
    "        x2=torch.zeros((np.shape(input)[0],3,288,384))\n",
    "        for i in range(np.shape(x2)[0]):\n",
    "            x2[i]=transform(np.array(input[0,:3].permute(1,2,0))*255)\n",
    "        y= transforms.Resize((288,384),antialias=True)(input[:,2:3])\n",
    "        ref=transforms.Resize((288,384),antialias=True)(ref)\n",
    "        res=model(x2.cuda(),y.cuda())\n",
    "        l=loss(res,ref.cuda())\n",
    "        eval_loss.append(l.cpu())\n",
    "    return eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c23824-400f-484f-ac16-f52bb5bcea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "L=evaluate(model,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b497f00-993d-45b3-af75-613f1d08b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloaders.dense_to_sparse as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de836ad-3cc7-4501-bcd5-8a37d3095959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(ds)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of intelisl_midas_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dldiy",
   "language": "python",
   "name": "dldiy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
